# 各种服务模型

目前存在的线程模型：

- 传统阻塞 IO 服务模型

- Reactor 模式

  根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现。

  - 单 Reactor 单线程
  - 单 Reactor 多线程
  - 主从 Reactor 多线程

Netty 主要基于主从 Reactor 多线程模型做了一定的改进，其中 Reactor 多线程模型有多个 Reactor。

> 传统阻塞 IO 问题：1.并发数很大，会创建大量的线程，占用很大系统资源。2.连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在 read 操作，造成线程资源浪费。

在目前的方案中，还存在一个问题就是，线程的粒度太大，每一个线程把一次交互的事情全部做了，包括读取和返回，甚至连接，表面上似乎连接不在线程里，但是如果线程不够，有了新的连接，也无法得到处理。

应该把一次连接的操作分为更细的粒度或者过程，虽然这样会使整个线程池的数目翻倍，但是线程更加简单，任务更加单一。

## Reactor 模式

基于 IO 复用模型，多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。

基于线程池复用线程资源，不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。

**在Reactor中，这些被拆分的小线程或者子过程对应的是handler，每一种handler会出处理一种event。这里会有一个全局的管理者selector，我们需要把channel注册感兴趣的事件，那么这个selector就会不断在channel上检测是否有该类型的事件发生，如果没有，那么主线程就会被阻塞，否则就会调用相应的事件处理函数即handler来处理。**典型的事件有连接，读取和写入，当然我们就需要为这些事件分别提供处理器，每一个处理器可以采用线程的方式实现。一个连接来了，显示被读取线程或者handler处理了，然后再执行写入，那么之前的读取就可以被后面的请求复用，吞吐量就提高了。

## reactor 模式的演化过程

![](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082644655-2144636819.png)

IO 会阻塞

1. serversocket 的 accept 方法，阻塞等待 client 连接，直到 client 连接成功。
2. 线程从 socket inputstream 读入数据，会进入阻塞状态，知道全部数据读完。
3. 线程像 socket outputstream 写入数据，会阻塞直到全部数据写完。

改进一：采用**基于事件驱动的设计**，当有事件触发时，才会调用处理器进行数据处理。 

**单 Reactor 单线程**

![](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082719280-29887948.png)

Reactor: 负责响应 IO 事件，当检测到一个新的事件，将其发送给相应的 Handler 去处理。

Handler：负责处理非阻塞的行为，表示系统管理的资源；同时将 handler 与事件绑定。

由于只有单个线程，所以处理器中的业务需要能够快速处理完。

改进二：使用**多线程**处理业务逻辑

**单 Reactor 多线程** 

![](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082834187-1581301551.png)

将处理器的执行放入线程池，多线程进行业务处理。但Reactor仍为单个线程。

改进三：将 Reactor 拆分为两部分

**主从 Reactor 多线程**

![](https://images0.cnblogs.com/blog2015/434101/201503/112151380898648.jpg)

为什么要单独分一个Reactor来处理监听呢？因为像TCP这样需要经过3次握手才能建立连接，这个建立连接的过程也是要耗时间和资源的，单独分一个Reactor来处理，可以提高性能。



## Netty 模型

Netty 基于主从 Reactor 多线程做了一定的改进，其中主从 Reactor 多线程模型有多个 Reactor。

![Netty.png](http://www.qxnekoo.cn:8888/images/2020/08/25/Netty.png)

1. Netty 抽象出两组线程池 BossGroup 专门负责接收客户端的连接，WorkerGroup 专门负责网络的读写。
2. BossGroup 和 WorkerGroup 类型都是 NIOEventLoopGroup。
3. NIOEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环都是 NIOEventLoop。
4. NIOEventLoop 表示一个不断循环的执行处理任务的线程，每个 NIOEventLoop 都有一个 selector，用于监听绑定在其上的 socket 网络通讯。
5. NIOEventLoopGroup 可以有多个线程，即可以含有多个 NIOEventLoop。
6. 每个 Boss NioEventLoop 循环执行的步骤：
   - 轮询 accept 事件
   - 处理 accept 事件，与 client 建立连接，生成 NIOSocketChannel,并将其注册到某个 worker NIOEventLoop 上的 selector
   - 处理任务队列的任务
7. 每个 Work NIOEventLoop 循环执行的步骤
   - 轮询 read、write 事件
   - 处理 IO 事件，即 read、write 事件，在对应的 NIOSocketChannel 处理
   - 处理任务队列的任务
8. 每个 Worker NIOEventLoop 处理业务时，会使用 pipeline（管道），pipeline 中包含了  channel，即通过 pipeline 可以获取到对应通道，管道中维护了很多的处理器。























